"""
ä¸»åº”ç”¨ç¨‹åº - é›†æˆUIå’ŒåŠŸèƒ½æ¨¡å—
"""

import gradio as gr
import torch

from config import (
    CUSTOM_CSS, HTML_HEADER, HTML_INFO, 
    HTML_IMAGE_UPLOAD, HTML_DETECTION_RESULT, 
    HTML_TEXT_QUERY, HTML_AI_ANALYSIS,
    USE_LOCAL_MODEL
)
from core.detection import process_detection, clear_inputs

# åˆ›å»ºGradioç•Œé¢
with gr.Blocks(title="LVLMç›®æ ‡æ£€æµ‹ç³»ç»Ÿ", theme=gr.themes.Soft(), css=CUSTOM_CSS) as app:

    # æ ‡é¢˜åŒºåŸŸ
    gr.HTML(HTML_HEADER)

    # ç³»ç»Ÿè¯´æ˜
    gr.HTML(HTML_INFO)



    # å›¾åƒä¸Šä¼ å’Œæ ‡æ³¨ç»“æœåŒºåŸŸ
    with gr.Row():
        with gr.Column(scale=1):
            gr.HTML(HTML_IMAGE_UPLOAD)
            image_input = gr.Image(
                label="è¾“å…¥å›¾åƒ",
                type="pil",
                height=500,
            )

        with gr.Column(scale=1):
            gr.HTML(HTML_DETECTION_RESULT)
            image_output = gr.Image(
                label="æ ‡æ³¨å›¾åƒ",
                height=460,
                show_download_button=True,
            )

    # æ–‡æœ¬æŸ¥è¯¢å’Œåˆ†æç»“æœåŒºåŸŸ
    with gr.Row():
        with gr.Column(scale=1):
            gr.HTML(HTML_TEXT_QUERY)
            text_input = gr.Textbox(
                show_label=False,
                placeholder="è¯·è¾“å…¥æ‚¨çš„æ£€æµ‹éœ€æ±‚ï¼Œä¾‹å¦‚ï¼š\nâ€¢ æ£€æµ‹å›¾åƒä¸­çš„äººç‰©\nâ€¢ è¯†åˆ«è½¦è¾†ç±»å‹\nâ€¢ ç»Ÿè®¡ç›®æ ‡æ•°é‡",
                lines=15,
                max_lines=15
            )

        with gr.Column(scale=1):
            gr.HTML(HTML_AI_ANALYSIS)
            text_output = gr.Markdown(
                label="ç³»ç»Ÿåˆ†æç»“æœ",
                value="æ¬¢è¿ä½¿ç”¨ç›®æ ‡æ£€æµ‹ç³»ç»Ÿï¼Œè¯·ä¸Šä¼ å›¾åƒå¹¶è¾“å…¥æŸ¥è¯¢å†…å®¹ã€‚",
                show_copy_button=True,
                height=250,
            )

    # æ§åˆ¶æŒ‰é’®
    with gr.Row():
        with gr.Column(scale=2):  # å·¦ä¾§ç©ºç™½
            gr.HTML("")
        with gr.Column(scale=3):  # æŒ‰é’®åŒºåŸŸ
            with gr.Row():
                detect_btn = gr.Button("ğŸš€ å¼€å§‹æ£€æµ‹", variant="primary")
                clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©º", variant="secondary")
        with gr.Column(scale=2):  # å³ä¾§ç©ºç™½
            gr.HTML("")

        # æ¨¡å‹é€‰æ‹©åŒºåŸŸ
    with gr.Row(visible=torch.cuda.is_available()):  # åªæœ‰åœ¨æœ‰GPUæ—¶æ‰æ˜¾ç¤ºæ¨¡å‹é€‰æ‹©
        with gr.Column(scale=1):
            gr.HTML("")
        with gr.Column(scale=3):
            with gr.Group(elem_classes=["model-toggle"]):
                model_choice = gr.Radio(
                    ["APIæ¨¡å¼", "æœ¬åœ°æ¨¡å¼"],
                    label="é€‰æ‹©LVLM",
                    value="APIæ¨¡å¼" if not USE_LOCAL_MODEL else "æœ¬åœ°æ¨¡å¼",
                    info="APIæ¨¡å¼éœ€è¦ç½‘ç»œè¿æ¥ï¼Œæœ¬åœ°æ¨¡å¼è‡³å°‘éœ€è¦ä¸€å¼ RTX 3090 24GB"
                )
        with gr.Column(scale=1):
            gr.HTML("")


    # æ¨¡å‹é€‰æ‹©åŠŸèƒ½
    def update_model_choice(choice):
        import importlib
        import sys
        
        # åŠ¨æ€ä¿®æ”¹é…ç½®
        config_module = sys.modules['main.config.config']
        setattr(config_module, 'USE_LOCAL_MODEL', choice == "æœ¬åœ°æ¨¡å‹æ¨¡å¼")
        
        # é‡æ–°åŠ è½½æ ¸å¿ƒæ¨¡å—ä»¥åº”ç”¨æ–°é…ç½®
        if 'main.core.detection' in sys.modules:
            importlib.reload(sys.modules['main.core.detection'])
        
        return f"å·²åˆ‡æ¢åˆ°{choice}ï¼Œè¯·ç‚¹å‡»æ£€æµ‹æŒ‰é’®è¿›è¡Œæµ‹è¯•ã€‚"

    model_choice.change(
        fn=update_model_choice,
        inputs=[model_choice],
        outputs=[text_output]
    )

    # äº‹ä»¶ç»‘å®š
    detect_btn.click(
        fn=process_detection,
        inputs=[image_input, text_input],
        outputs=[text_output, image_output]
    )

    clear_btn.click(
        fn=clear_inputs,
        inputs=[],
        outputs=[image_input, text_input, text_output, image_output]
    )

    # æ”¯æŒå›è½¦é”®è§¦å‘æ£€æµ‹
    text_input.submit(
        fn=process_detection,
        inputs=[image_input, text_input],
        outputs=[text_output, image_output]
    )

# å¯åŠ¨åº”ç”¨
if __name__ == "__main__":
    # æ£€æŸ¥æ˜¯å¦æœ‰CUDAæ”¯æŒ
    if USE_LOCAL_MODEL and not torch.cuda.is_available():
        print("è­¦å‘Šï¼šæœ¬åœ°æ¨¡å‹æ¨¡å¼éœ€è¦CUDAæ”¯æŒï¼Œä½†æœªæ£€æµ‹åˆ°å¯ç”¨çš„GPUã€‚å°†è‡ªåŠ¨åˆ‡æ¢åˆ°APIæ¨¡å¼ã€‚")
        # åŠ¨æ€ä¿®æ”¹é…ç½®
        import sys
        config_module = sys.modules['main.config.config']
        setattr(config_module, 'USE_LOCAL_MODEL', False)
    
    app.launch(
        share=False,
        debug=True,
        server_name="127.0.0.1",
        server_port=7860
    )