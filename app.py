import importlib

import gradio as gr
import torch

from config import *
from core.detect import detect, clear

# åˆ›å»ºGradioç•Œé¢
with gr.Blocks(title="LVLMç›®æ ‡æ£€æµ‹ç³»ç»Ÿ", theme=gr.themes.Soft(), css=CSS) as app:
    # æ ‡é¢˜åŒºåŸŸ
    gr.HTML(HTML_HEADER)
    # ç³»ç»Ÿè¯´æ˜
    gr.HTML(HTML_INFO)
    # å›¾åƒä¸Šä¼ å’Œæ ‡æ³¨ç»“æœåŒºåŸŸ
    with gr.Row():
        with gr.Column(scale=1):
            gr.HTML(HTML_IMAGE_UPLOAD)
            image_input = gr.Image(label="è¾“å…¥å›¾åƒ",
                                   type="pil",
                                   height=500)

        with gr.Column(scale=1):
            gr.HTML(HTML_DETECTION_RESULT)
            image_output = gr.Image(label="æ ‡æ³¨å›¾åƒ",
                                    height=460,
                                    show_download_button=True)
    # æ–‡æœ¬æŸ¥è¯¢å’Œåˆ†æç»“æœåŒºåŸŸ
    with gr.Row():
        with gr.Column(scale=1):
            gr.HTML(HTML_TEXT_QUERY)
            text_input = gr.Textbox(show_label=False,
                                    placeholder="è¯·è¾“å…¥æ‚¨çš„æ£€æµ‹éœ€æ±‚ã€‚",
                                    lines=15,
                                    max_lines=15)

        with gr.Column(scale=1):
            gr.HTML(HTML_AI_ANALYSIS)
            text_output = gr.Markdown(label="åˆ†æç»“æœ",
                                      value="è¯·ä¸Šä¼ å›¾åƒå¹¶è¾“å…¥æŸ¥è¯¢å†…å®¹ã€‚",
                                      show_copy_button=True,
                                      height=250)
    # æ§åˆ¶æŒ‰é’®
    with gr.Row():
        with gr.Column(scale=2):  # å·¦ä¾§ç©ºç™½
            gr.HTML("")
        with gr.Column(scale=3):  # æŒ‰é’®åŒºåŸŸ
            with gr.Row():
                detect_btn = gr.Button("ğŸš€ æ£€æµ‹", variant="primary")
                clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©º", variant="secondary")
        with gr.Column(scale=2):  # å³ä¾§ç©ºç™½
            gr.HTML("")

    # æ¨¡å‹é€‰æ‹©
    with gr.Row(visible=torch.cuda.is_available()):
        with gr.Column(scale=1):
            gr.HTML("")
        with gr.Column(scale=3):
            with gr.Group(elem_classes=["model-toggle"]):
                model_choice = gr.Radio(["APIæ¨¡å¼", "æœ¬åœ°æ¨¡å¼"],
                                        label="é€‰æ‹©LVLM",
                                        value="APIæ¨¡å¼" if not USE_LOCAL_MODEL else "æœ¬åœ°æ¨¡å¼",
                                        info="APIæ¨¡å¼éœ€è¦ç½‘ç»œè¿æ¥ï¼Œæœ¬åœ°æ¨¡å¼è‡³å°‘éœ€è¦ä¸€å¼ RTX 3090 24GB")
        with gr.Column(scale=1):
            gr.HTML("")


    def update_model_choice(choice):
        import sys
        # åŠ¨æ€ä¿®æ”¹é…ç½®
        config_module = sys.modules['config']
        setattr(config_module, 'USE_LOCAL_MODEL', choice == "æœ¬åœ°æ¨¡å¼")

        # é‡æ–°åŠ è½½æ ¸å¿ƒæ¨¡å—ä»¥åº”ç”¨æ–°é…ç½®
        if 'core.detect' in sys.modules:
            importlib.reload(sys.modules['core.detect'])

        return f"å·²åˆ‡æ¢åˆ°{choice}ã€‚"


    model_choice.change(fn=update_model_choice,
                        inputs=[model_choice],
                        outputs=[text_output])

    # äº‹ä»¶ç»‘å®š
    detect_btn.click(fn=detect,
                     inputs=[image_input, text_input],
                     outputs=[text_output, image_output])

    clear_btn.click(fn=clear,
                    inputs=[],
                    outputs=[image_input, text_input, text_output, image_output])

    # å›è½¦é”®
    text_input.submit(fn=detect,
                      inputs=[image_input, text_input],
                      outputs=[text_output, image_output])

# å¯åŠ¨åº”ç”¨
if __name__ == "__main__":
    if USE_LOCAL_MODEL and not torch.cuda.is_available():
        print("æœ¬åœ°æ¨¡å¼éœ€è¦CUDAæ”¯æŒï¼Œä½†æœªæ£€æµ‹åˆ°å¯ç”¨çš„GPUã€‚å°†è‡ªåŠ¨åˆ‡æ¢åˆ°APIæ¨¡å¼ã€‚")
        import sys

        config_module = sys.modules['config']
        setattr(config_module, 'USE_LOCAL_MODEL', False)

    app.launch(share=True,
               debug=True,
               server_name="127.0.0.1",
               server_port=7860)
